services:
  # Job scraper service - Seek platform
  scraper-seek:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: jobly-scraper-seek
    command: python scripts/run_scraper.py --scraper seek
    env_file:
      - .env
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Job scraper service - Prosple platform
  scraper-prosple:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: jobly-scraper-prosple
    command: python scripts/run_scraper.py --scraper prosple
    env_file:
      - .env
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Job scraper service - GradConnection platform
  scraper-gradconnection:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: jobly-scraper-gradconnection
    command: python scripts/run_scraper.py --scraper gradconnection
    env_file:
      - .env
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Job processor service - analyzes unanalyzed jobs with LLM
  processor:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: jobly-processor
    command: python scripts/run_processor.py
    env_file:
      - .env
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Uncomment to limit resources if needed
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '1.0'
    #       memory: 1G
